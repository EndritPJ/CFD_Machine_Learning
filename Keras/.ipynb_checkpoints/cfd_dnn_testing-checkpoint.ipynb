{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2196f2e",
   "metadata": {},
   "source": [
    "# Testing ML models for predicting CFD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad3281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re, time, random\n",
    "import copy as cp\n",
    "import numpy as np\n",
    "import statistics, scipy\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.patheffects as PathEffects\n",
    "matplotlib.rcParams['figure.dpi']= 200\n",
    "matplotlib.rcParams.update({'font.size': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2bbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b060521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27607e",
   "metadata": {},
   "source": [
    "## <span style='background :yellow' > Import Shape Modelling PCA Data </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to .csv with shape mode csvs\n",
    "ssm_pca_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c10be9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssm_file = open(ssm_pca_path, \"r\")\n",
    "ssm_df = pd.read_csv(ssm_file, header=None, index_col=False)\n",
    "ssm_pca_u = ssm_df.to_numpy()\n",
    "print(np.shape(ssm_pca_u))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67092a",
   "metadata": {},
   "source": [
    "**keep only first X modes (99% cumvar)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm_pca_u = ssm_pca_u[:, :35]\n",
    "print(np.shape(ssm_pca_u))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096f1ae",
   "metadata": {},
   "source": [
    "## <span style='background :yellow' > Import CFD Data </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8fc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human sorting function\n",
    "\n",
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "def alphanum_key(s):\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "\n",
    "def sort_nicely(l):\n",
    "    l.sort(key=alphanum_key)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to folder with cfd point cloud csvs in point correspondence\n",
    "cfd_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b75172",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = sort_nicely(os.listdir(cfd_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94ff5d",
   "metadata": {},
   "source": [
    "**import all csv flow fields (keep columns 1: pressure, 3: velocity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build array of csv files\n",
    "cfd_files = sort_nicely(os.listdir(cfd_path))\n",
    "cfd_data = []\n",
    "cfd_empty = [] # only x,y,z\n",
    "\n",
    "for fn in cfd_files:\n",
    "    file = open(cfd_path + fn, \"r\")\n",
    "    df = pd.read_csv(file, index_col=False)\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "    # build list of cfd or empty dataframes\n",
    "    df_cfd = df.drop(df.columns[[2, 3, 4]], axis=1)\n",
    "    df_empty = df.drop(df.columns[[0, 1]], axis=1)\n",
    "    cfd_data.append(df_cfd.values)\n",
    "    cfd_empty.append(df_empty.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfd_data[subject][node][pressure/velocity]\n",
    "cfd_data = np.array(cfd_data)\n",
    "\n",
    "# p_data[subject][node_pressure]\n",
    "p_data = np.squeeze(cfd_data[:, :, :1])\n",
    "v_data = np.squeeze(cfd_data[:, :, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f25544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of subjects, no. of pressure nodes (features)\n",
    "np.shape(p_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45b94c",
   "metadata": {},
   "source": [
    "### <span style='background :yellow' > SPLIT DATASET </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = 2800\n",
    "test_n = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data_test = p_data[train_n:]\n",
    "v_data_test = v_data[train_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcef537",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ssm_pca_u[:train_n]\n",
    "X_test = ssm_pca_u[train_n:]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03038cfb",
   "metadata": {},
   "source": [
    "# <span style='background :yellow' > DNN PREDICTION </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8768c",
   "metadata": {},
   "source": [
    "**Import models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f74620",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_attempt = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e370f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.getcwd() + \"/Run_\" + str(run_attempt) + \"/model/\"\n",
    "\n",
    "# load S and Vt matrices (needed for estimators)\n",
    "S_p_tensor = tf.convert_to_tensor(np.load(model_dir + 'S_p.npy'))\n",
    "S_v_tensor = tf.convert_to_tensor(np.load(model_dir + 'S_v.npy'))\n",
    "Vt_p_tensor = tf.convert_to_tensor(np.load(model_dir + 'Vt_p.npy'))\n",
    "Vt_v_tensor = tf.convert_to_tensor(np.load(model_dir + 'Vt_v.npy'))\n",
    "\n",
    "# load pipeline\n",
    "pipeline_loaded = joblib.load(model_dir + 'pipeline.pkl')\n",
    "scaler_p = pipeline_loaded[0]\n",
    "scaler_v = pipeline_loaded[1]\n",
    "\n",
    "# load estimators\n",
    "dnn_p = keras.models.load_model(model_dir + \"dnn_p.h5\")\n",
    "dnn_v = keras.models.load_model(model_dir + \"dnn_v.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f7b1fb-4500-443d-a0e1-a1ea81bf652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output save directory\n",
    "\n",
    "data_dir = model_dir.replace(\"model/\", \"predictions/\")\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8c13b",
   "metadata": {},
   "source": [
    "**Pressure**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a74f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict standardised data\n",
    "P_pred = dnn_p.predict(X_test)\n",
    "\n",
    "# reverse standardisation\n",
    "P_pred_inv_scaling = scaler_p.inverse_transform(P_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ca26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(P_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e02599",
   "metadata": {},
   "source": [
    "**Velocity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e00770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict standardised data\n",
    "V_pred = dnn_v.predict(X_test)\n",
    "\n",
    "# inverse standardisation \n",
    "V_pred_inv_scaling = scaler_v.inverse_transform(V_pred)\n",
    "# make all negatives = 0\n",
    "V_pred_inv_scaling_no_negatives = np.clip(V_pred_inv_scaling, a_min=0, a_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7affe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(V_pred_inv_scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91844d7",
   "metadata": {},
   "source": [
    "**Stack together prediction results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_empty_csv = cfd_empty[train_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a40c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predictions to csv\n",
    "pred_csv = np.dstack((pred_empty_csv, P_pred_inv_scaling))\n",
    "pred_csv = np.dstack((pred_csv, V_pred_inv_scaling_no_negatives))\n",
    "\n",
    "# calculate P and V errors and add them to csv\n",
    "errors_p, errors_v = [], []\n",
    "for i in range(len(pred_csv)):\n",
    "    err_p = abs(np.subtract(pred_csv[i, :, 3], p_data[i+train_n, :]))\n",
    "    err_v = abs(np.subtract(pred_csv[i, :, 4], v_data[i+train_n, :]))\n",
    "    errors_p.append(err_p)\n",
    "    errors_v.append(err_v)\n",
    "    \n",
    "pred_csv = np.dstack((pred_csv, errors_p))\n",
    "pred_csv = np.dstack((pred_csv, errors_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(pred_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aef50b2",
   "metadata": {},
   "source": [
    "## <span style='background :yellow' > Inspecting Errors </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa0481",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = fnames[train_n:]\n",
    "test_filenames = [s.replace(\"_ext.csv\", \"\") for s in test_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13506c69-1021-4c56-ae67-0af43092b049",
   "metadata": {},
   "source": [
    "**get matrix of subject errors (rows=subjects)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ffda8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pressure_pred_evaluation = pd.DataFrame(columns=['filename', 'range_true (Pa)', 'MAE (Pa)', 'NMAE (%)'])\n",
    "for i in range(p_data_test.shape[0]):\n",
    "    MAE = mean_absolute_error(p_data_test[i], P_pred_inv_scaling[i])\n",
    "    p_range = max(p_data_test[i]) - min(p_data_test[i])\n",
    "    pressure_pred_evaluation.loc[i] = [test_filenames[i], p_range, MAE, MAE*100/p_range]\n",
    "    \n",
    "velocity_pred_evaluation = pd.DataFrame(columns=['filename', 'range_true (m/s)', 'MAE (m/s)', 'NMAE (%)'])\n",
    "for i in range(v_data_test.shape[0]):\n",
    "    MAE = mean_absolute_error(v_data_test[i], V_pred_inv_scaling_no_negatives[i])\n",
    "    v_range = max(v_data_test[i]) - min(v_data_test[i])\n",
    "    velocity_pred_evaluation.loc[i] = [test_filenames[i], v_range, MAE, MAE*100/v_range]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da793fe4",
   "metadata": {},
   "source": [
    "**MAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average MAE = \" + \"{:.2f}\".format(np.mean(pressure_pred_evaluation['MAE (Pa)'])) + \" Pa\")\n",
    "print(\"StDev = \" + \"{:.2f}\".format(statistics.stdev(pressure_pred_evaluation['MAE (Pa)'])) + \" Pa\")\n",
    "print(\"\")\n",
    "print(\"average MAE = \" + \"{:.2f}\".format(np.mean(velocity_pred_evaluation['MAE (m/s)'])) + \" m/s\")\n",
    "print(\"StDev = \" + \"{:.2f}\".format(statistics.stdev(velocity_pred_evaluation['MAE (m/s)'])) + \" m/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"value of max MAE = \" + \"{:.2f}\".format(max(pressure_pred_evaluation['MAE (Pa)'])) + \" Pa\")\n",
    "print(\"index of max MAE = \" + str(np.argmax(pressure_pred_evaluation['MAE (Pa)'])))\n",
    "print(\"value of min MAE = \" + \"{:.2f}\".format(min(pressure_pred_evaluation['MAE (Pa)'])) + \" Pa\")\n",
    "print(\"index of min MAE = \" + str(np.argmin(pressure_pred_evaluation['MAE (Pa)'])))\n",
    "print(\"\")\n",
    "print(\"value of max MAE = \" + \"{:.2f}\".format(max(velocity_pred_evaluation['MAE (m/s)'])) + \" m/s\")\n",
    "print(\"index of max MAE = \" + str(np.argmax(velocity_pred_evaluation['MAE (m/s)'])))\n",
    "print(\"value of min MAE = \" + \"{:.2f}\".format(min(velocity_pred_evaluation['MAE (m/s)'])) + \" m/s\")\n",
    "print(\"index of min MAE = \" + str(np.argmin(velocity_pred_evaluation['MAE (m/s)'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098bbd4",
   "metadata": {},
   "source": [
    "**NMAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c985545",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average NMAE = \" + \"{:.2f}\".format(np.mean(pressure_pred_evaluation['NMAE (%)'])) + \" %\")\n",
    "print(\"StDev = \" + \"{:.2f}\".format(statistics.stdev(pressure_pred_evaluation['NMAE (%)'])) + \" %\")\n",
    "print(\"\")\n",
    "print(\"average NMAE = \" + \"{:.2f}\".format(np.mean(velocity_pred_evaluation['NMAE (%)'])) + \" %\")\n",
    "print(\"StDev = \" + \"{:.2f}\".format(statistics.stdev(velocity_pred_evaluation['NMAE (%)'])) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ff201",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"value of max NMAE = \" + \"{:.2f}\".format(max(pressure_pred_evaluation['NMAE (%)'])) + \" %\")\n",
    "print(\"index of max NMAE = \" + str(np.argmax(pressure_pred_evaluation['NMAE (%)'])))\n",
    "print(\"value of min NMAE = \" + \"{:.2f}\".format(min(pressure_pred_evaluation['NMAE (%)'])) + \" %\")\n",
    "print(\"index of min NMAE = \" + str(np.argmin(pressure_pred_evaluation['NMAE (%)'])))\n",
    "print(\"\")\n",
    "print(\"value of max NMAE = \" + \"{:.2f}\".format(max(velocity_pred_evaluation['NMAE (%)'])) + \" %\")\n",
    "print(\"index of max NMAE = \" + str(np.argmax(velocity_pred_evaluation['NMAE (%)'])))\n",
    "print(\"value of min NMAE = \" + \"{:.2f}\".format(min(velocity_pred_evaluation['NMAE (%)'])) + \" %\")\n",
    "print(\"index of min NMAE = \" + str(np.argmin(velocity_pred_evaluation['NMAE (%)'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff1291-a4bf-4808-8aa6-7fece287d0d1",
   "metadata": {},
   "source": [
    "## <span style='background :yellow' > Box Plots </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553c3ed-6ae5-47dc-beea-737fecbfefbe",
   "metadata": {},
   "source": [
    "Subject-wise errors (SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7640b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "\n",
    "ax.boxplot([pressure_pred_evaluation['NMAE (%)'], \n",
    "               velocity_pred_evaluation['NMAE (%)']], \n",
    "               labels=[\"Pressure\", \"Velocity Magnitude\"],\n",
    "               flierprops=dict(marker='.'),\n",
    "               medianprops=dict(color='r'),\n",
    "               showfliers=False)\n",
    "ax.set(title=\"Pressure and Velocity DNN errors (NMAE)\", ylabel = \"NMAE (%)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9111da-8094-4104-8314-4368b2156402",
   "metadata": {},
   "source": [
    "Node-wise errors (NE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368108ae-4df1-4184-98cc-638bbc9504f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(2, 3))\n",
    "\n",
    "# compute range of pressure/velocity values per subject\n",
    "# use OVERALL ao range for each node\n",
    "ranges_p = np.ptp(p_data_test, axis=1)\n",
    "ranges_v = np.ptp(v_data_test, axis=1)\n",
    "\n",
    "p_data_flatten_errors = abs(p_data_test.flatten() - P_pred_inv_scaling.flatten())\n",
    "v_data_flatten_errors = abs(v_data_test.flatten() - V_pred_inv_scaling.flatten())\n",
    "\n",
    "p_data_flatten_errors = p_data_flatten_errors * 100 / np.repeat(ranges_p, p_data_test[0].shape[0])\n",
    "v_data_flatten_errors = v_data_flatten_errors * 100 / np.repeat(ranges_v, v_data_test[0].shape[0])\n",
    "\n",
    "p_data_flatten_errors = p_data_flatten_errors.reshape((p_data_test.shape[0], p_data_test.shape[1]))\n",
    "v_data_flatten_errors = v_data_flatten_errors.reshape((v_data_test.shape[0], v_data_test.shape[1]))\n",
    "\n",
    "p_data_flatten_errors = np.mean(p_data_flatten_errors, axis=0)\n",
    "v_data_flatten_errors = np.mean(v_data_flatten_errors, axis=0)\n",
    "\n",
    "ax.boxplot([p_data_flatten_errors, \n",
    "               v_data_flatten_errors], \n",
    "               labels=[\"Pressure\", \"Velocity Magnitude\"],\n",
    "               showfliers=False,\n",
    "               widths=0.3,\n",
    "               flierprops=dict(marker='.'),\n",
    "               medianprops=dict(color='r'))\n",
    "ax.set(title=\"Pressure and Velocity DNN errors (NMAE)\", ylabel = \"NMAE (%)\")\n",
    "\n",
    "print(np.median(p_data_flatten_errors))\n",
    "print(np.median(v_data_flatten_errors))\n",
    "print(np.percentile(p_data_flatten_errors, [25, 75])[1] - np.percentile(p_data_flatten_errors, [25, 75])[0])\n",
    "print(np.percentile(v_data_flatten_errors, [25, 75])[1] - np.percentile(v_data_flatten_errors, [25, 75])[0])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7d5923-c9a6-4d20-898f-565cee98bf97",
   "metadata": {},
   "source": [
    "Node-wise errors (NE) with no averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9971d88b-5fe8-458c-b370-22a87bbb3b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO averaging, concat all subjects then do pred vs true errors and plot\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "\n",
    "p_data_flatten_errors = abs(p_data_test.flatten() - P_pred_inv_scaling.flatten())\n",
    "v_data_flatten_errors = abs(v_data_test.flatten() - V_pred_inv_scaling.flatten())\n",
    "\n",
    "p_data_flatten_errors = p_data_flatten_errors * 100 / np.repeat(ranges_p, p_data_test[0].shape[0])\n",
    "v_data_flatten_errors = v_data_flatten_errors * 100 / np.repeat(ranges_v, v_data_test[0].shape[0])\n",
    "\n",
    "ax.boxplot([p_data_flatten_errors, \n",
    "               v_data_flatten_errors], \n",
    "               labels=[\"Pressure\", \"Velocity Magnitude\"],\n",
    "               showfliers=False,\n",
    "               flierprops=dict(marker='.'),\n",
    "               medianprops=dict(color='r'))\n",
    "ax.set(title=\"Pressure and Velocity DNN errors (NMAE)\", ylabel = \"NMAE (%)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1e8bf",
   "metadata": {},
   "source": [
    "## <span style='background :yellow' > Shape mode vs Subject Error </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d950b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_0vsP = scipy.stats.pearsonr(X_test[:, 0], pressure_pred_evaluation['NMAE (%)'])\n",
    "R_1vsP = scipy.stats.pearsonr(X_test[:, 1], pressure_pred_evaluation['NMAE (%)'])\n",
    "R_2vsP = scipy.stats.pearsonr(X_test[:, 2], pressure_pred_evaluation['NMAE (%)'])\n",
    "R_0vsV = scipy.stats.pearsonr(X_test[:, 0], velocity_pred_evaluation['NMAE (%)'])\n",
    "R_1vsV = scipy.stats.pearsonr(X_test[:, 1], velocity_pred_evaluation['NMAE (%)'])\n",
    "R_2vsV = scipy.stats.pearsonr(X_test[:, 2], velocity_pred_evaluation['NMAE (%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(4.5, 3))\n",
    "\n",
    "ax[0][0].scatter(X_test[:, 0]*8, pressure_pred_evaluation['NMAE (%)'], s=0.1, c=\"k\", marker=\"o\")\n",
    "ax[0][0].set_ylabel(\"Pressure SE (%)\")\n",
    "ax[0][0].set_title(\"R = \"+\"{:.2f}\".format(R_0vsP[0])+\"            p = \"+\"{:.2f}\".format(R_0vsP[1]), fontsize=6, pad=0.2, y=1.02)\n",
    "ax[0][0].set_xlim(left=-2, right=2)\n",
    "\n",
    "ax[0][1].scatter(X_test[:, 1]*8, pressure_pred_evaluation['NMAE (%)'], s=0.1, c=\"k\")\n",
    "ax[0][1].set_title(\"R = \"+\"{:.2f}\".format(R_1vsP[0])+\"            p = \"+\"{:.2f}\".format(R_1vsP[1]), fontsize=6, pad=0.2, y=1.02)\n",
    "ax[0][1].set_xlim(left=-2, right=2)\n",
    "\n",
    "ax[0][2].scatter(X_test[:, 2]*8, pressure_pred_evaluation['NMAE (%)'], s=0.1, c=\"k\")\n",
    "ax[0][2].set_title(\"R = \"+\"{:.2f}\".format(R_2vsP[0])+\"            p = \"+\"{:.2f}\".format(R_2vsP[1]), fontsize=6, pad=0.2, y=1.02)\n",
    "ax[0][2].set_xlim(left=-2, right=2)\n",
    "\n",
    "ax[1][0].scatter(X_test[:, 0]*8, velocity_pred_evaluation['NMAE (%)'], s=0.1, c=\"k\")\n",
    "ax[1][0].set(xlabel=\"Shape mode 1\"+\"\\n\"+\"Standard deviations\")\n",
    "ax[1][0].set_ylabel(\"Velocity SE (%)\")\n",
    "ax[1][0].set_title(\"R = \"+\"{:.2f}\".format(R_0vsV[0])+\"            p = \"+\"{:.0e}\".format(R_0vsV[1]), fontsize=6, pad=0.2, y=1.02)\n",
    "ax[1][0].set_xlim(left=-2, right=2)\n",
    "\n",
    "ax[1][1].scatter(X_test[:, 1]*8, velocity_pred_evaluation['NMAE (%)'], s=0.1, c=\"k\")\n",
    "ax[1][1].set(xlabel=\"Shape mode 2\"+\"\\n\"+\"Standard deviations\")\n",
    "ax[1][1].set_title(\"R = \"+\"{:.2f}\".format(R_1vsP[0])+\"            p = \"+\"{:.0e}\".format(R_1vsV[1]), fontsize=6, pad=0.2, y=1.02)\n",
    "ax[1][1].set_xlim(left=-2, right=2)\n",
    "\n",
    "ax[1][2].scatter(X_test[:, 2]*8, velocity_pred_evaluation['NMAE (%)'], s=0.1, c=\"k\")\n",
    "ax[1][2].set(xlabel=\"Shape mode 3\"+\"\\n\"+\"Standard deviations\")\n",
    "ax[1][2].set_title(\"R = \"+\"{:.2f}\".format(R_2vsV[0])+\"            p = \"+\"{:.0e}\".format(R_2vsV[1]), fontsize=6, pad=0.2, y=1.02)\n",
    "ax[1][2].set_xlim(left=-2, right=2)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bf9afd",
   "metadata": {},
   "source": [
    "## <span style='background :yellow' > Saving Predictions </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419fcd3e",
   "metadata": {},
   "source": [
    "**Save csv file of metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a111803",
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_pred_evaluation.to_csv(data_dir+\"evaluation_pressure.csv\", sep='\\t')\n",
    "velocity_pred_evaluation.to_csv(data_dir+\"evaluation_velocity.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee98987",
   "metadata": {},
   "source": [
    "**Save predicted point clouds as csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred_csv)):\n",
    "    pred_full_csv = pd.DataFrame(pred_csv[i])\n",
    "    pred_full_csv.rename(columns={0: 'x', 1: 'y', 2: 'z', 3: 'Pressure_pred_(Pa)', 4: 'Velocity_pred_(m/s)', \n",
    "                            5: 'Pressure_error_(Pa)', 6: 'Velocity_error_(m/s)'}, inplace=True)\n",
    "    pred_full_csv.to_csv(data_dir + \"pred_\" + str(fnames[i+train_n]) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2710bef-0900-4e93-a04d-3ad6dec34651",
   "metadata": {},
   "source": [
    "**Average predictions and average errors, visualised on template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e991ec7-1005-4e7f-8884-8ba11dd17423",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtu_template_path = \"template_vtu_points.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8800d-26d4-43b5-88ce-86820d0623cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtu_template_csv = open(vtu_template_path, \"r\")\n",
    "df_template = pd.read_csv(vtu_template_csv, header=None, index_col=None)\n",
    "df_template = df_template.drop(df_template.columns[0], axis=1) \n",
    "df_template = df_template.drop([0], axis=0)\n",
    "template_np = np.array(df_template).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aacd9b2-98d0-45d3-9a64-ee7bb68c0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mean (check variable p_data_flatten_errors correspond to correct error)\n",
    "stacked = np.c_[template_np, p_data_flatten_errors]\n",
    "stacked = np.c_[stacked, v_data_flatten_errors]\n",
    "new_csv = pd.DataFrame(stacked)\n",
    "new_csv.rename(columns={0: 'x', 1: 'y', 2: 'z', 3: 'Node-averaged Pressure Errors (%)', 4: 'Node-averaged Velocity Errors (%)'}, inplace=True)\n",
    "\n",
    "new_csv.to_csv(data_dir + \"average_pred_errors.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-env",
   "language": "python",
   "name": "keras-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
