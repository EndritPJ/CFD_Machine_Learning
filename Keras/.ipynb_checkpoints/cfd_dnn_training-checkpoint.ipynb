{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2196f2e",
   "metadata": {},
   "source": [
    "# Training ML models to predict CFD \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad3281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re, time\n",
    "import copy as cp\n",
    "import numpy as np\n",
    "import statistics, scipy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi']= 200\n",
    "matplotlib.rcParams.update({'font.size': 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27607e",
   "metadata": {},
   "source": [
    "## <span style='background :yellow' > Import Shape Modelling PCA Data </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dab17b-2e68-4974-984f-9e121e7f9ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to .csv file with shape mode scores\n",
    "ssm_pca_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c10be9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssm_file = open(ssm_pca_path, \"r\")\n",
    "ssm_df = pd.read_csv(ssm_file, header=None, index_col=False)\n",
    "ssm_pca_u = ssm_df.to_numpy()\n",
    "print(np.shape(ssm_pca_u))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67092a",
   "metadata": {},
   "source": [
    "**keep only first X modes (99% cumvar)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe8537-4ad6-41e2-b720-607a3ef6a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm_modes_n = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm_pca_u = ssm_pca_u[:, :ssm_modes_n]\n",
    "print(np.shape(ssm_pca_u))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096f1ae",
   "metadata": {},
   "source": [
    "## <span style='background :yellow' > Import CFD Data </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8fc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human sorting function\n",
    "\n",
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "def alphanum_key(s):\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "\n",
    "def sort_nicely(l):\n",
    "    l.sort(key=alphanum_key)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to folder containing CFD simulations in total point correspondence\n",
    "cfd_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b75172",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = sort_nicely(os.listdir(cfd_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94ff5d",
   "metadata": {},
   "source": [
    "**import all csv flow fields (keep columns 1: pressure, 3: velocity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build array of csv files\n",
    "cfd_files = sort_nicely(os.listdir(cfd_path))\n",
    "cfd_data = []\n",
    "cfd_empty = [] # only x,y,z\n",
    "\n",
    "for fn in cfd_files:\n",
    "    file = open(cfd_path + fn, \"r\")\n",
    "    df = pd.read_csv(file, index_col=False)\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "    # pressure/velocity df\n",
    "    df_cfd = df.drop(df.columns[[2, 3, 4]], axis=1)\n",
    "    # points xyz df\n",
    "    df_empty = df.drop(df.columns[[0, 1]], axis=1)\n",
    "    cfd_data.append(df_cfd.values)\n",
    "    cfd_empty.append(df_empty.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfd_data[subject][node][pressure/velocity]\n",
    "cfd_data = np.array(cfd_data)\n",
    "\n",
    "# p_data[subject][node_pressure]\n",
    "p_data = np.squeeze(cfd_data[:, :, :1])\n",
    "v_data = np.squeeze(cfd_data[:, :, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f25544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 594 subjects, 27420 pressure nodes (features)\n",
    "np.shape(p_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45b94c",
   "metadata": {},
   "source": [
    "### <span style='background :yellow' > SPLIT DATASET </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = 2800\n",
    "test_n = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(ssm_pca_u, train_size=train_n, shuffle=False)\n",
    "\n",
    "p_data_train, p_data_test = train_test_split(p_data, train_size=train_n, shuffle=False)\n",
    "\n",
    "v_data_train, v_data_test = train_test_split(v_data, train_size=train_n, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a872d",
   "metadata": {},
   "source": [
    "# <span style='background :pink' > PCA ON CFD *TRAINING* DATA </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4faa0de",
   "metadata": {},
   "source": [
    "#### rows=training subjects, columns=features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764f358a",
   "metadata": {},
   "source": [
    "### Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ed89fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# center each feature\n",
    "scaler_p = StandardScaler(with_std=True)\n",
    "\n",
    "# fit scaler on TRAINING (including VALIDATION) set\n",
    "p_data_train_scaled = scaler_p.fit_transform(p_data_train)\n",
    "\n",
    "p_data_test_scaled = scaler_p.transform(p_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute PCA\n",
    "U_p, S_p, Vt_p = np.linalg.svd(p_data_train_scaled, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get cumulative variance (start from mode 0)\n",
    "Keep adding modes until 99% variance captured\n",
    "'''\n",
    "cumvar_p = np.cumsum(S_p**2) / sum(S_p**2)\n",
    "cumvar_p[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faaf353",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes_p = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d3eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "U matrix is [subjects, scores(per mode)]\n",
    "(not needed in training)\n",
    "'''\n",
    "p_data_pca_train = (U_p[:, :n_modes_p])\n",
    "p_data_pca_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f1766",
   "metadata": {},
   "source": [
    "### Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_v = StandardScaler(with_std=True)\n",
    "\n",
    "v_data_train_scaled = scaler_v.fit_transform(v_data_train)\n",
    "\n",
    "v_data_test_scaled = scaler_v.transform(v_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e5aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute PCA\n",
    "U_v, S_v, Vt_v = np.linalg.svd(v_data_train_scaled, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee43dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Capturing variance much more difficult for velocity\n",
    "'''\n",
    "cumvar_v = np.cumsum(S_v**2) / sum(S_v**2)\n",
    "cumvar_v[:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes_v = 55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b005f923",
   "metadata": {},
   "source": [
    "### Finalise train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b132fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_train, P_test = p_data_train_scaled, p_data_test_scaled\n",
    "V_train, V_test = v_data_train_scaled, v_data_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8618503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train: \"+str(X_train.shape)+\" X_test: \" + str(X_test.shape))\n",
    "print(\"\")\n",
    "print(\"P_train: \"+str(P_train.shape)+\" P_test: \"+str(P_test.shape))\n",
    "print(\"V_train: \"+str(V_train.shape)+\" V_test: \" + str(V_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3898bd66",
   "metadata": {},
   "source": [
    "# <span style='background :pink' > DEEP LEARNING </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2bbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"tensorflow version: \" + str(tf.__version__))\n",
    "print(\"keras version: \" + str(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace313c9",
   "metadata": {},
   "source": [
    "**define lambda layer for inverse PCA as a DNN layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get S and V matrices in tensor type\n",
    "S_p_tensor = tf.convert_to_tensor(S_p)\n",
    "Vt_p_tensor = tf.convert_to_tensor(Vt_p)\n",
    "S_v_tensor = tf.convert_to_tensor(S_v)\n",
    "Vt_v_tensor = tf.convert_to_tensor(Vt_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_pressure_pca(x):\n",
    "    x = tf.cast(x, tf.float64)\n",
    "    n_modes = x.get_shape().as_list()[1]\n",
    "    x_inv = tf.matmul(tf.matmul(x, tf.linalg.diag(S_p_tensor[:n_modes])), Vt_p_tensor[:n_modes, :])\n",
    "    return x_inv\n",
    "\n",
    "def inv_velocity_pca(x):\n",
    "    x = tf.cast(x, tf.float64)\n",
    "    n_modes = x.get_shape().as_list()[1]\n",
    "    x_inv = tf.matmul(tf.matmul(x, tf.linalg.diag(S_v_tensor[:n_modes])), Vt_v_tensor[:n_modes, :])\n",
    "    return x_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa91ff6",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' > HYPERPARAMETER OPTIMISATION </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d091e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import plotly\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb874cf5",
   "metadata": {},
   "source": [
    "### <span style='background :lightgreen' > Initial Search </span>\n",
    "\n",
    "Conduct initial coarse grid search for pressure and velocity in order to narrow down search space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b73cd8c",
   "metadata": {},
   "source": [
    "Assign fixed train/validation folds for sklearn.  \n",
    "\n",
    "Take out portion of training set to make a fixed validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac5d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.full((train_n-test_n,), -1, dtype=int)\n",
    "val_indices = np.full((test_n,), 0, dtype=int)\n",
    "train_val_fold = np.append(train_indices, val_indices)\n",
    "\n",
    "print(train_val_fold)\n",
    "print(train_val_fold.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f31fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PredefinedSplit(train_val_fold)\n",
    "ps.get_n_splits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653db715-77ff-4f37-a1a1-485bc4813e35",
   "metadata": {},
   "source": [
    "Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_p(NUM_LAYERS, NUM_UNITS, LEARN_RATE):\n",
    "    INPUT = ssm_modes_n\n",
    "    OUTPUT = n_modes_p\n",
    "    model = keras.models.Sequential()\n",
    "    # input layer\n",
    "    model.add(keras.layers.Dense(INPUT, activation=\"relu\"))\n",
    "    # hidden layers\n",
    "    for layer in range(NUM_LAYERS):\n",
    "        model.add(keras.layers.Dense(NUM_UNITS, activation=\"relu\"))                                     \n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(OUTPUT, activation=\"linear\"))\n",
    "    # inverse pca\n",
    "    model.add(keras.layers.Lambda(inv_pressure_pca))\n",
    "    # optimiser and loss\n",
    "    model.compile(loss=\"mae\", optimizer='adam', run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d852288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_v(NUM_LAYERS, NUM_UNITS, LEARN_RATE):\n",
    "    INPUT = ssm_modes_n\n",
    "    OUTPUT = n_modes_v\n",
    "    model = keras.models.Sequential()\n",
    "    # input layer\n",
    "    model.add(keras.layers.Dense(INPUT, activation=\"relu\"))\n",
    "    # hidden layers\n",
    "    for layer in range(NUM_LAYERS):\n",
    "        model.add(keras.layers.Dense(NUM_UNITS, activation=\"relu\"))                                     \n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(OUTPUT, activation=\"linear\"))\n",
    "    # inverse pca\n",
    "    model.add(keras.layers.Lambda(inv_velocity_pca))\n",
    "    # optimiser and loss\n",
    "    model.compile(loss=\"mae\", optimizer='adam', run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5466255",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p_grid = KerasRegressor(build_fn=build_model_p, epochs=100)\n",
    "model_v_grid = KerasRegressor(build_fn=build_model_v, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da131137",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'NUM_LAYERS': [4, 5, 6], \n",
    "   'NUM_UNITS' : [200, 400, 600],\n",
    "   'LEARN_RATE': [1e-4, 5e-4, 1e-3],\n",
    "   'batch_size': [32]\n",
    "  }]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e70623f-8b72-4ab3-bb9d-f497e04a0b9f",
   "metadata": {},
   "source": [
    "Fit Pressure Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566741b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_p = GridSearchCV(estimator=model_p_grid, param_grid=param_grid, cv=ps, verbose=1)\n",
    "\n",
    "gs_p = gs_p.fit(X_train, P_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_p.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_p.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edac46c2-2f3c-4d56-90ab-8d6ab9867592",
   "metadata": {},
   "source": [
    "Fit Velocity Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea4c65",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs_v = GridSearchCV(estimator=model_v_grid, param_grid=param_grid, cv=ps, verbose=1)\n",
    "\n",
    "gs_v = gs_v.fit(X_train, V_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_v.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_v.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0932bf1",
   "metadata": {},
   "source": [
    "### <span style='background :lightgreen' > Cross Validation </span>\n",
    "\n",
    "2nd round of hyperparam search.  \n",
    "\n",
    "refine models around initial search result and perform 5-fold CV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41a9d30",
   "metadata": {},
   "source": [
    "### Models CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2fb2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_p_cv(trial):\n",
    "    INPUT = ssm_modes_n\n",
    "    OUTPUT = n_modes_p\n",
    "    # hyperparams\n",
    "    NUM_LAYERS = trial.suggest_int(\"n_layers\", 4, 8, step=1)\n",
    "    NUM_UNITS = trial.suggest_int(\"n_units\", 300, 500, step=25)\n",
    "    LEARN_RATE = trial.suggest_loguniform(\"learn_rate\", 1e-5, 5e-3)\n",
    "    # model\n",
    "    model = keras.models.Sequential()\n",
    "    # input layer\n",
    "    model.add(keras.layers.Dense(INPUT, activation=\"relu\"))\n",
    "    # hidden layers\n",
    "    for layer in range(NUM_LAYERS):\n",
    "        model.add(keras.layers.Dense(NUM_UNITS, activation=\"relu\"))                                     \n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(OUTPUT, activation=\"linear\"))\n",
    "    # inverse pca\n",
    "    model.add(keras.layers.Lambda(inv_pressure_pca))\n",
    "    # optimiser and loss\n",
    "    model.compile(loss=\"mae\", optimizer='adam', run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b34624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_v_cv(trial):\n",
    "    INPUT = ssm_modes_n\n",
    "    OUTPUT = n_modes_v\n",
    "    # hyperparams\n",
    "    NUM_LAYERS = trial.suggest_int(\"n_layers\", 5, 8, step=1)\n",
    "    NUM_UNITS = trial.suggest_int(\"n_units\", 100, 200, step=10)\n",
    "    LEARN_RATE = trial.suggest_loguniform(\"learn_rate\", 5e-4, 5e-3)\n",
    "    # model\n",
    "    model = keras.models.Sequential()\n",
    "    # input layer\n",
    "    model.add(keras.layers.Dense(INPUT, activation=\"relu\"))\n",
    "    # hidden layers\n",
    "    for layer in range(NUM_LAYERS):\n",
    "        model.add(keras.layers.Dense(NUM_UNITS, activation=\"relu\"))                                     \n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(OUTPUT, activation=\"linear\"))\n",
    "    # inverse pca\n",
    "    model.add(keras.layers.Lambda(inv_velocity_pca))\n",
    "    # optimiser and loss\n",
    "    model.compile(loss=\"mae\", optimizer='adam', run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8673f9",
   "metadata": {},
   "source": [
    "### Objectives CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a978ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_p_cv(trial):\n",
    "    \n",
    "    NUM_FOLDS = 5\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 32\n",
    "    kfold = KFold(n_splits=NUM_FOLDS)\n",
    "    \n",
    "    cv_scores=[]\n",
    "    for train_i, test_i in kfold.split(X_train):\n",
    "        # pressure data\n",
    "        x_train, x_valid = X_train[train_i], X_train[test_i]\n",
    "        y_train, y_valid = P_train[train_i], P_train[test_i]\n",
    "        \n",
    "        model = build_model_p_cv(trial)\n",
    "        \n",
    "        model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[optuna.integration.TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "                   tf.keras.callbacks.EarlyStopping(patience=10)],\n",
    "        verbose=1)\n",
    "        \n",
    "        score = model.evaluate(x_valid, y_valid, verbose=1)\n",
    "        cv_scores.append(score)\n",
    "    \n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e6009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_v_cv(trial):\n",
    "    \n",
    "    NUM_FOLDS = 5\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 32\n",
    "    kfold = KFold(n_splits=NUM_FOLDS)\n",
    "    \n",
    "    cv_scores=[]\n",
    "    for train_i, test_i in kfold.split(X_train):\n",
    "        # pressure data\n",
    "        x_train, x_valid = X_train[train_i], X_train[test_i]\n",
    "        y_train, y_valid = V_train[train_i], V_train[test_i]\n",
    "        \n",
    "        model = build_model_v_cv(trial)\n",
    "        \n",
    "        model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[optuna.integration.TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "                   tf.keras.callbacks.EarlyStopping(patience=10)],\n",
    "        verbose=1)\n",
    "        \n",
    "        score = model.evaluate(x_valid, y_valid, verbose=1)\n",
    "        cv_scores.append(score)\n",
    "    \n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5787498a",
   "metadata": {},
   "source": [
    "### Pressure CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2a114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study_p_cv = optuna.create_study(direction=\"minimize\", \n",
    "                              sampler=optuna.samplers.TPESampler(), \n",
    "                              pruner=optuna.pruners.HyperbandPruner())\n",
    "\n",
    "study_p_cv.optimize(objective_p_cv, n_trials=250, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90467b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials_p_cv = study_p_cv.get_trials(deepcopy=False, states=[optuna.trial.TrialState.PRUNED])\n",
    "complete_trials_p_cv = study_p_cv.get_trials(deepcopy=False, states=[optuna.trial.TrialState.COMPLETE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study_p_cv.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials_p_cv))\n",
    "print(\"  Number of complete trials: \", len(complete_trials_p_cv))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study_p_cv.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_intermediate_values(study_p_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31205e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_p_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e06bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study_p_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study_p_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab92bc",
   "metadata": {},
   "source": [
    "### Velocity CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c568611a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study_v_cv = optuna.create_study(direction=\"minimize\", \n",
    "                              sampler=optuna.samplers.TPESampler(), \n",
    "                              pruner=optuna.pruners.HyperbandPruner())\n",
    "\n",
    "study_v_cv.optimize(objective_v_cv, n_trials=250, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials_v_cv = study_v_cv.get_trials(deepcopy=False, states=[optuna.trial.TrialState.PRUNED])\n",
    "complete_trials_v_cv = study_v_cv.get_trials(deepcopy=False, states=[optuna.trial.TrialState.COMPLETE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study_v_cv.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials_v_cv))\n",
    "print(\"  Number of complete trials: \", len(complete_trials_v_cv))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study_v_cv.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a564e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_intermediate_values(study_v_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54123c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_v_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f33350",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study_v_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6c7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study_v_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c963746",
   "metadata": {},
   "source": [
    "# <span style='background :red' > TRAINING TUNED MODELS </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1002b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_attempt = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd541d0",
   "metadata": {},
   "source": [
    "**TensorBoard Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.getcwd() + \"/Tensorflow/my_logs/\"\n",
    "\n",
    "# make a path using date/time\n",
    "def get_run_logdir(metric):\n",
    "    run_id = \"run \" + str(run_attempt) + \"__\" + time.strftime(\"run_%Y_%m_%d__%H-%M\") + \"__\" + metric\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49578cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_p_logdir = get_run_logdir(\"Pressure\")\n",
    "tensorboard_v_logdir = get_run_logdir(\"Velocity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1607fcc",
   "metadata": {},
   "source": [
    "**DNN Model Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5f9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.getcwd() + \"/Run_\" + str(run_attempt) + \"/model/\"\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75a4c4",
   "metadata": {},
   "source": [
    "**Define and Train Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ae9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tuned_pressure_model():\n",
    "    INPUT = ssm_modes_n\n",
    "    OUTPUT = n_modes_p\n",
    "    # hyperparameters from tuning\n",
    "    NUM_LAYERS = study_p_cv.best_trial.params[\"n_layers\"]\n",
    "    NUM_UNITS = study_p_cv.best_trial.params[\"n_units\"]\n",
    "    LEARN_RATE = study_p_cv.best_trial.params[\"learn_rate\"]\n",
    "    # model\n",
    "    model = keras.models.Sequential()\n",
    "    # input layer\n",
    "    model.add(keras.layers.Dense(INPUT, activation=\"relu\"))\n",
    "    # hidden layers\n",
    "    for layer in range(NUM_LAYERS):\n",
    "        model.add(keras.layers.Dense(NUM_UNITS, activation=\"relu\"))                                     \n",
    "    # output layer - cfd pca\n",
    "    model.add(keras.layers.Dense(OUTPUT, activation=\"linear\"))\n",
    "    # pca conversion\n",
    "    model.add(keras.layers.Lambda(inv_pressure_pca))\n",
    "    # compile\n",
    "    model.compile(loss=\"mae\", optimizer=\"adam\", run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d0d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tuned_velocity_model():\n",
    "    INPUT = ssm_modes_n\n",
    "    OUTPUT = n_modes_v\n",
    "    # hyperparameters from tuning\n",
    "    NUM_LAYERS = study_v_cv.best_trial.params[\"n_layers\"]\n",
    "    NUM_UNITS = study_v_cv.best_trial.params[\"n_units\"]\n",
    "    LEARN_RATE = study_v_cv.best_trial.params[\"learn_rate\"]\n",
    "    # model\n",
    "    model = keras.models.Sequential()\n",
    "    # input layer\n",
    "    model.add(keras.layers.Dense(INPUT, activation=\"relu\"))\n",
    "    # hidden layers\n",
    "    for layer in range(NUM_LAYERS):\n",
    "        model.add(keras.layers.Dense(NUM_UNITS, activation=\"relu\"))                                     \n",
    "    # output layer - cfd pca\n",
    "    model.add(keras.layers.Dense(OUTPUT, activation=\"linear\"))\n",
    "    # pca conversion\n",
    "    model.add(keras.layers.Lambda(inv_velocity_pca))\n",
    "    # compile\n",
    "    model.compile(loss=\"mae\", optimizer=\"adam\", run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf487fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train pressure NN\n",
    "dnn_p = build_tuned_pressure_model()\n",
    "\n",
    "dnn_p.fit(X_train, \n",
    "          P_train, \n",
    "          epochs=1000, \n",
    "          batch_size=32,\n",
    "          validation_split=0.1, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=1000),\n",
    "                     keras.callbacks.ModelCheckpoint(model_dir+\"/dnn_p.h5\", \n",
    "                                                     monitor=\"val_loss\", \n",
    "                                                     save_best_only=True),\n",
    "                     keras.callbacks.TensorBoard(log_dir=tensorboard_p_logdir, histogram_freq=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9afcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train velocity NN\n",
    "dnn_v = build_tuned_velocity_model()\n",
    "\n",
    "dnn_v.fit(X_train, \n",
    "          V_train, \n",
    "          epochs=1000,\n",
    "          batch_size=32,           \n",
    "          validation_split=0.1, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=1000),                                                    \n",
    "                     keras.callbacks.ModelCheckpoint(model_dir+\"/dnn_v.h5\", \n",
    "                                                     monitor=\"val_loss\", \n",
    "                                                     save_best_only=True),\n",
    "                     keras.callbacks.TensorBoard(log_dir=tensorboard_v_logdir, histogram_freq=1)])                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a480a580",
   "metadata": {},
   "source": [
    "**Tensorboard Visualisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50eb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember, set smoothing to 0\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./Tensorflow/my_logs/ --port=6007"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff01c03",
   "metadata": {},
   "source": [
    "**Saving Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# save scalers in model dir\n",
    "pipeline = Pipeline([\n",
    "    # output\n",
    "    ('scaler_p', scaler_p),\n",
    "    ('scaler_v', scaler_v)\n",
    "])\n",
    "joblib.dump(pipeline, model_dir + 'pipeline.pkl')\n",
    "\n",
    "# save U, S and Vt matrices in model dir\n",
    "np.save(model_dir+'U_p', U_p, allow_pickle=True)\n",
    "np.save(model_dir+'S_p', S_p, allow_pickle=True)\n",
    "np.save(model_dir+'Vt_p', Vt_p, allow_pickle=True)\n",
    "np.save(model_dir+'U_v', U_v, allow_pickle=True)\n",
    "np.save(model_dir+'S_v', S_v, allow_pickle=True)\n",
    "np.save(model_dir+'Vt_v', Vt_v, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-env",
   "language": "python",
   "name": "keras-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
